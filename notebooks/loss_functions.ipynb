{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "### Outline:\n",
    "- This notebook will derive the forward (loss function calculation) and backward (derivative of loss function with respect to the prediction $\\hat{y}$) mathematical formulas of various loss functions in machine learning.\n",
    "- Python implementation of both forward and backward\n",
    "\n",
    "### Motivation for loss functions\n",
    "\n",
    "The role of a loss function is to measure the \"gap\" between true labels and predicted labels. The \"gap\" is intentionally very vague, because every loss function has its own definition of \"gap\". Once we figure out the \"gap\", we need our models to learn to adjust itself to be \"correct more\" next time. This is where the \"backward\" or derivative of the loss function comes into play. \n",
    "\n",
    "### How loss functions help the model learn from its mistake\n",
    "\n",
    "For a model with parameters $\\theta$, the model parameter update rule (a.k.a Gradient Descent Update) is:\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)} = \\theta^{(t)} - \\eta \\, \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "or\n",
    "$$\n",
    "\\theta_{new} = \\theta_{old} - \\eta \\, \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\theta^{(t)}$ is the parameter/weight vector at iteration $t$,\n",
    "- $\\eta$ is the learning rate,\n",
    "- $\\frac{\\partial L}{\\partial \\theta}$ is the gradient of the loss function $L$ with respect to the parameters $\\theta$.\n",
    "\n",
    "\n",
    "They are connected through the chain rule. In a real model, you never update $\\hat{y}$ directly; you update the parameters $\\theta$ so that the output $\\hat{y} = f(x; \\theta)$ gets closer to the target $y$.\n",
    "\n",
    "Remember, by the chain rule, we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "And we know that $\\hat{y} = f(x; \\theta)$, so if $x$ doesn't change, we are modeling the relationship between $\\theta$ and $\\hat{y}$.\n",
    "\n",
    "If you imagine a case where the relationship between $\\theta$ and $\\hat{y}$ is simple (say, $\\hat{y}$ is a linear function of $\\theta$ so that $\\frac{\\partial \\hat{y}}{\\partial \\theta}$ behaves like an identity function), then the update on $\\theta$ results in a change in $\\hat{y}$ that is (up to scaling) the same as directly subtracting $\\eta \\frac{\\partial L}{\\partial \\hat{y}}$. That is, conceptually you can write\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{y}_{new} &= f(x; \\theta_{new}) \\\\\n",
    "&= f(x; \\theta_{old} - \\eta \\, \\frac{\\partial L}{\\partial \\theta}) \\\\\n",
    "&\\approx \\hat{y}_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial \\hat{y}} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Note:** The last equation is an oversimplified version, which doesn't always hold if $f$ is non-linear, which is often the case. It's used to conceptually illustrate the model learning process with respect to the gradients of the loss functions $L$.\n",
    "- If $\\frac{\\partial L}{\\partial \\hat{y}}$ is positive (indicating $\\hat{y}$ is too high), the update subtracts a positive quantity, thus decreasing $\\hat{y}$.\n",
    "- If $\\frac{\\partial L}{\\partial \\hat{y}}$ is negative (indicating $\\hat{y}$ is too low), subtracting a negative value increases $\\hat{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy\n",
    "Also known as: \"Log Loss\" or \"negative log-likelihood\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward\n",
    "$$\n",
    "- \\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log{\\hat{y_i}} + (1 - y_i) \\log{(1 - \\hat{y_i})} \\right]\n",
    "$$\n",
    "\n",
    "Where \n",
    "- $N$ is the total number of samples\n",
    "- $y_i$ is the true label (0 or 1) for the $i$-th sample\n",
    "- $\\hat{y_i}$ is the predicted probability for the $i$-th sample\n",
    "\n",
    "The formulation of this loss function actually comes from how we model the probability mass function (PMF) of a Bernoulli-distributed random variable $Y$, which represents a binary outcome of 0 or 1.\n",
    "The likelihood of $Y$ taking on a specific value of $y$ (either 0 or 1) is:\n",
    "\n",
    "$$\n",
    "P(Y = y) = p^y (1 - p)^{1-y}\n",
    "$$\n",
    "\n",
    "Then if we take the log-likelihood of $Y$:\n",
    "$$\n",
    "log P(Y = y) = y \\log (p) + (1-y) \\log (1 - p)\n",
    "$$\n",
    "\n",
    "In our machine learning world, we want to maximize this likelihood for our model to correctly model this distribution. But since gradient descent usually is concerned with minimizing the loss function, we will convert this problem from: **maximize log likelihood** to **minimize negative log likelihood**, so we take the negation of that, which gives us exactly the first formula known as the \"Binary Cross Entropy\" loss:\n",
    "$$\n",
    "- \\left[ y \\log{\\hat{y}} + (1 - y) \\log{(1 - \\hat{y})} \\right]\n",
    "$$\n",
    "\n",
    "Then we can divide it by the number of samples $N$ in an iteration. I will omit that here since it's exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.] [0.99       0.46340523 0.14644962 0.91515728]\n",
      "raw_bce=array([0.01005034, 0.76915337, 1.92107383, 0.08865934])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6972342200251623)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.ones((4,))\n",
    "y_pred = np.random.rand(4)\n",
    "y_pred[0] = 0.99 # make the first prediction close to true label of 1\n",
    "print(y_true, y_pred)\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred, reduce=\"mean\"):\n",
    "    raw_bce = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    print(f\"{raw_bce=}\")\n",
    "    if reduce == \"mean\":\n",
    "        return np.mean(raw_bce)\n",
    "    elif reduce == \"sum\":\n",
    "        return np.sum(raw_bce)\n",
    "\n",
    "binary_cross_entropy(y_true, y_pred) # the first sample's loss should be close to 0, while the others are higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward\n",
    "\n",
    "Recall\n",
    "$$\n",
    "\\text{BCE} = - \\left[ y \\log{\\hat{y}} + (1 - y) \\log{(1 - \\hat{y})} \\right] \\\\\n",
    "$$\n",
    "\n",
    "Compute the derivative separate for the two terms:\n",
    "$$\n",
    "\\frac{\\partial y \\log \\hat{y}}{\\partial \\hat{y}} = y \\cdot \\frac{1}{\\hat{y}} \\\\\n",
    "\\frac{\\partial (1 - y) \\log{(1 - \\hat{y})}}{\\partial \\hat{y}} = (1 - y) \\cdot \\frac{-1}{1-\\hat{y}} \\\\\n",
    "$$\n",
    "\n",
    "Combine terms\n",
    "$$\n",
    "\\frac{\\partial \\text{BCE}}{\\partial \\hat{y}} = - \\left( y \\cdot \\frac{1}{\\hat{y}} + (1 - y) \\cdot \\frac{-1}{1-\\hat{y}} \\right) \\\\\n",
    "\n",
    "= - \\frac{y}{\\hat{y}} + \\frac{1 - y}{1-\\hat{y}} \\\\\n",
    "\n",
    "= \\frac{(1 - y)(\\hat{y}) - y(1 - \\hat{y})}{\\hat{y} (1 - \\hat{y})} \\\\\n",
    "\n",
    "= \\frac{\\hat{y} - y}{\\hat{y} (1 - \\hat{y})}\n",
    "$$\n",
    "\n",
    "Now we can see that:\n",
    "\n",
    "- when $y = 1$, the gradient simplifies to $-\\frac{1}{\\hat{y}}$, which is very negative when $\\hat{y}$ is small, and pushing $\\hat{y}$ upwards closer to $y = 1$\n",
    "- when $y = 0$, the gradient simplifies to $\\frac{1}{1 - \\hat{y}}$, which is very positive when $\\hat{y}$ is large, and pushing $\\hat{y}$ downwards closer to $y = 0$\n",
    "\n",
    "The pushing of $\\hat{y}$ can be seen with this update function\n",
    "$$\n",
    "\\hat{y}_{new} = \\hat{y}_{old} - \\text{learning rate} \\cdot \\frac{\\partial \\text{BCE}}{\\partial \\hat{y}}\n",
    "$$\n",
    "\n",
    "- So you can see, when the gradient is very positive, we push $\\hat{y}$ downwards closer to $y = 0$.\n",
    "- when the gradient is very negative, we push $\\hat{y}$ upwards closer to $y = 1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.] [0.99       0.46340523 0.14644962 0.91515728]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.01010101, -2.15793851, -6.82828697, -1.09270835])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bce_backward(y_true, y_pred):\n",
    "    return (y_pred - y_true) / (y_pred * (1 - y_pred))\n",
    "\n",
    "print(y_true, y_pred)\n",
    "bce_backward(y_true, y_pred) # We should see that the gradient of the elements except the first element will be very negative, so it will push y_pred closer to y = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy\n",
    "\n",
    "Let's generalize to the cross entropy loss formula, which can be used to compute the difference between two probability distributions.\n",
    "\n",
    "We will try to be consistent in the notation, in case we get lost, these notations are equivalent:\n",
    "- $p_{true}$ = $y_{true}$\n",
    "- $p_{pred}$ = $y_{pred}$ = $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are couple of ways to compute the cross entropy loss depending on the type of inputs we pass in. We will discuss each one separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. probabilities for $y_{pred}$ and one-hot encoding for $y_{true}$\n",
    "\n",
    "Inputs:\n",
    "- $y_{true}$: A **one-hot** encoded vector representing the true class (e.g., [0, 1, 0] for class 2).\n",
    "- $y_{pred}$: A probability distribution over classes (typically obtained by applying softmax to logits).\n",
    "\n",
    "What It Does:\n",
    "- The formula  $-\\sum_{c} y_{\\text{true},c} \\log(y_{\\text{pred},c})$  is the general definition of cross entropy.\n",
    "- In a **one-hot** scenario, only the term corresponding to the correct class contributes to the loss, so it simplifies to  $-\\log(\\hat{y}_{\\text{correct}})$.\n",
    "\n",
    "Loss:\n",
    "$$\n",
    "\\text{CE} = -\\sum_{c} y_{\\text{true}, c} \\,\\log \\bigl(y_{\\text{pred}, c}\\bigr).\n",
    "$$\n",
    "\n",
    "In a one-hot scenario, only the term corresponding to the correct class contributes, so it simplifies to\n",
    "\n",
    "$$\n",
    "-\\log \\bigl(y_{\\text{pred}, t}\\bigr)\n",
    "$$\n",
    "\n",
    "where $t$ is the target class index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward\n",
    "\n",
    "Let's recall the binary cross entropy formula when $C = 2$:\n",
    "\n",
    "$$\n",
    "y_1 = y \\; \\text{and} \\; y_0 = 1-y \\\\\n",
    "\\hat{y}_1 = \\hat{y} \\; \\text{and} \\; \\hat{y}_0 = 1-\\hat{y} \\\\\n",
    "\\text{Cross Entropy} = \\text{Binary Cross Entropy} = -\\Bigl[y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y})\\Bigr]\n",
    "$$\n",
    "\n",
    "When we have more than 2 classes, let's denote the number of classes as $C$:\n",
    "\n",
    "$$\n",
    "\n",
    "\\text{Cross Entropy (CE)}\n",
    "= -\\sum_{c} y_{\\text{true}, c} \\,\\log \\bigl(y_{\\text{pred}, c}\\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_bce=array([0.01005034, 0.76915337, 1.92107383, 0.08865934])\n",
      "2.7889368801006493 0.6972342200251623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_one_hot(y_true, y_pred):\n",
    "    return - np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "ce = cross_entropy_one_hot(y_true, y_pred)\n",
    "bce = binary_cross_entropy(y_true, y_pred)\n",
    "print(ce, bce)\n",
    "np.sum(bce) == ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. logits for $y_{pred}$ and target index for $y_{true}$\n",
    "\n",
    "Inputs:\n",
    "- $\\mathbf{z} = (z_1, \\dots, z_C)$ are the logits (raw scores) from the model.\n",
    "- $t$ (an integer) is the index of the correct class.\n",
    "\n",
    "What happens internally:\n",
    "- Numerical Stability: It subtracts the maximum logit from all logits before exponentiating. This is the log-sum-exp trick that helps prevent numerical overflow.\n",
    "- Internally computes softmax which converts logits into a probability distribution $\\hat{y}_j = \\frac{e^{z_j}}{\\sum{k} e^{z_k}}$\n",
    "\n",
    "\n",
    "\n",
    "Since the true label is given as an index, the loss is computed as:\n",
    "\n",
    "$$\n",
    "\\text{Cross Entropy} = -\\log(y_{pred, t}) = -\\log \\biggl( \\text{softmax}(\\text{logits}_{target}) \\biggr) = -\\log \\biggl( \\frac{e^{z_t}}{\\sum_j e^{z_j}} \\biggr)\n",
    "$$\n",
    "\n",
    "Where $t$ is the target class' index, and $j$ is the all the classes\n",
    "\n",
    "This matches the generic cross entropy definition in the one-hot case (only the target class term contributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8619948040582511 [0.1553624 0.4223188 0.4223188]\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_logits(logits, target_index):\n",
    "    max_logit = np.max(logits)\n",
    "    stable_logits = logits - max_logit\n",
    "    \n",
    "    exp_logits = np.exp(stable_logits)\n",
    "    softmax = exp_logits / np.sum(exp_logits)\n",
    "    \n",
    "    loss = - np.log(softmax[target_index])\n",
    "    return loss, softmax\n",
    "\n",
    "loss, softmax = cross_entropy_logits(np.array([1,2,2]), 1)\n",
    "\n",
    "print(loss, softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward\n",
    "\n",
    "We first consider the derivative of the cross entropy with respect to the predicted probability $y_{\\text{pred}}$ for the target class t:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{CE}}{\\partial y_{\\text{pred}, t}}\n",
    "= - \\frac{\\partial}{\\partial y_{\\text{pred}, t}} \\bigl[\\log(y_{\\text{pred}, t})\\bigr]\n",
    "= -\\frac{1}{y_{\\text{pred}, t}}.\n",
    "$$\n",
    "\n",
    "For any other class $j \\neq t, y_{\\text{true}, j} = 0$, so the loss does not directly depend on $y_{\\text{pred}, j}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{CE}}{\\partial y_{\\text{pred}, j}}\n",
    "= 0 \\quad \\text{(for } j \\neq t\\text{)}.\n",
    "$$\n",
    "\n",
    "**Gradient with Respect to Logits ($z_i$)**\n",
    "\n",
    "Recall that\n",
    "\n",
    "$$\n",
    "\\text{CE} = -\\log\\!\\Bigl(\\frac{e^{z_t}}{\\sum_{j} e^{z_j}}\\Bigr)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "y_{\\text{pred}, i} = \\frac{e^{z_i}}{\\sum_{k} e^{z_k}}\n",
    "$$\n",
    "\n",
    "By applying the chain rule (and using the known derivative of softmax), we arrive at the well-known result for all classes i:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{CE}}{\\partial z_i} = y_{\\text{pred}, i} - y_{\\text{true}, i}\n",
    "$$\n",
    "\n",
    "**In more detail:**\n",
    "\n",
    "1.\tSoftmax Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_{\\text{pred}, i}}{\\partial z_j} = y_{\\text{pred}, i}\\,\\bigl(\\delta_{ij} - y_{\\text{pred}, j}\\bigr)\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\delta_{ij}$ is the Kronecker delta (1 if $i=j$, 0 otherwise).\n",
    "\n",
    "2.\tChain Rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{CE}}{\\partial z_i}\n",
    "= \\sum_{j} \\frac{\\partial \\text{CE}}{\\partial y_{\\text{pred}, j}}\n",
    "\\cdot \\frac{\\partial y_{\\text{pred}, j}}{\\partial z_i}\n",
    "$$\n",
    "\n",
    "Only the term for $j = t$ is nonzero in $\\frac{\\partial \\text{CE}}{\\partial y_{\\text{pred}, j}}$. Substituting and simplifying leads to\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\text{CE}}{\\partial z_i} &= \\bigl(y_{\\text{pred}, i} - \\delta_{it}\\bigr)\n",
    "&= y_{\\text{pred}, i} - y_{\\text{true}, i}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The pushing of $\\hat{y}$ can be seen with this update function\n",
    "$$\n",
    "\\hat{y}_{new} = \\hat{y}_{old} - \\text{learning rate} \\cdot \\frac{\\partial \\text{CE}}{\\partial \\hat{y}}\n",
    "$$\n",
    "\n",
    "1.\tTarget Class ($i = t$):\n",
    "    $$\n",
    "    \\frac{\\partial \\text{CE}}{\\partial z_t} = y_{\\text{pred}, t} - 1\n",
    "    $$\n",
    "\n",
    "    If $y_{\\text{pred}, t} < 1$, this gradient is negative, indicating $z_t$ should increase (raising the probability of the correct class).\n",
    "\n",
    "2.\tNon-Target Classes ($i \\neq t$):\n",
    "    $$\n",
    "    \\frac{\\partial \\text{CE}}{\\partial z_i} = y_{\\text{pred}, i}\n",
    "    $$\n",
    "\n",
    "    A positive gradient means $z_i$ should decrease to lower the probability for incorrect classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1553624 -0.5776812  0.4223188] [0.1553624 0.4223188 0.4223188]\n"
     ]
    }
   ],
   "source": [
    "def grad_cross_entropy(softmax, target_index):\n",
    "    grad = softmax.copy()\n",
    "    grad[target_index] -= 1  # Subtract 1 for the target index\n",
    "    return grad\n",
    "\n",
    "grad = grad_cross_entropy(softmax, target_index=1)\n",
    "print(grad, softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "Also known as: \"L2 loss\"\n",
    "\n",
    "The Mean Squared Error measures the average of the squares of the errors between the predicted values and the actual values. Usually used in solving regression problems.\n",
    "\n",
    "1.\tPunishing Outliers\n",
    "    - Because of the squaring, MSE penalizes larger deviations heavily, making the model try very hard to avoid large mistakes. This can be good if you truly want to push the model to be accurate across all samples, but it can also make MSE sensitive to outliers.\n",
    "2.\tRelationship to Variance\n",
    "    - Minimizing MSE is related to minimizing variance (in the simplest case of linear models, it also ties in neatly with least squares solutions).\n",
    "3.\tCommon Use Cases\n",
    "    - Classic linear regression.\n",
    "    - Neural networks for regression outputs (e.g., predicting continuous values).\n",
    "    - Any scenario where the average squared difference is a sensible measure of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of samples\n",
    "- $y_i$ is the true label (regression target) for the $i$-th sample\n",
    "- $\\hat{y}_i$ is the predicted value for the $i$-th sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5625\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([3.0, -1.0, 2.0, 7.0])\n",
    "y_pred = np.array([2.5, -2.0, 2.0, 8.0])\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "mse_value = mean_squared_error(y_true, y_pred)\n",
    "print(\"MSE:\", mse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward\n",
    "\n",
    "We want the derivative of MSE with respect to $\\hat{y}_i$:\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial \\hat{y}_i}\n",
    "= \\frac{\\partial}{\\partial \\hat{y}_i} \\left( \\frac{1}{N} \\sum_{j=1}^N (y_j - \\hat{y}_j)^2 \\right)\n",
    "= \\frac{2}{N} (\\hat{y}_i - y_i)\n",
    "$$\n",
    "\n",
    "In vectorized form for all samples:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\hat{y}} \\text{MSE} = \\frac{2}{N} (\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "The pushing of $\\hat{y}$ can be seen with this update function\n",
    "$$\n",
    "\\hat{y}_{new} = \\hat{y}_{old} - \\text{learning rate} \\cdot \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}}\n",
    "$$\n",
    "\n",
    "\n",
    "- Proportional Error Correction: The gradient is directly proportional to the difference $\\hat{y} - y$. If the prediction $\\hat{y}$ is much higher than the target $y$, the gradient is large and positive (by the formula couple lines above), signaling the model to decrease its prediction. Conversely, if $\\hat{y}$ is too low, the gradient is large and negative, pushing the prediction upward.\n",
    "- Smooth and Symmetric: Because the error is squared, the penalty increases quadratically with the error size. This smooth, continuous gradient helps the optimizer make fine adjustments, especially as predictions get closer to the true values.\n",
    "- Diminishing Updates: As the model improves and the error decreases, the gradient becomes smaller, resulting in smaller updates. This is helpful for fine-tuning the model as it converges toward the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE gradient: [-0.25 -0.5   0.    0.5 ]\n"
     ]
    }
   ],
   "source": [
    "def mse_backward(y_true, y_pred):\n",
    "    # N is the number of samples\n",
    "    N = y_true.size\n",
    "    return 2.0 * (y_pred - y_true) / N\n",
    "\n",
    "mse_grad = mse_backward(y_true, y_pred)\n",
    "print(\"MSE gradient:\", mse_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss\n",
    "\n",
    "Commonly used in support vector machines and other “maximum-margin” methods for classification problems. Assumes labels ($\\pm 1$).\n",
    "\n",
    "We will try to give an overview without going to Support Vector Machine details.\n",
    "\n",
    "**Key characteristics:**\n",
    "1.\tMargin Enforcement\n",
    "    - The condition $y \\hat{y} \\ge 1$ means the data point is not just classified correctly $y \\hat{y}>0$ but also lies outside the margin boundary $\\text{distance} \\ge \\frac{1}{\\|\\mathbf{w}\\|}$.\n",
    "    - When $y \\hat{y} \\ge 1$, the hinge loss is 0, indicating “no penalty” if the point is on the correct side with some margin.\n",
    "2.\tFocus on Hard Examples\n",
    "    - If a sample is correctly classified and beyond the margin, it doesn’t contribute to the loss or gradient.\n",
    "    - Only misclassified or within-margin points incur a penalty, making the training more focused on the “hard” or borderline cases.\n",
    "3.\tLinear Gradient\n",
    "    - For points within the margin, the gradient is constant $-y$. This leads to sub-gradient methods for optimization (SVM solvers).\n",
    "4.\tUse Cases\n",
    "    - SVM classification (especially linear or kernel SVMs).\n",
    "    - Sometimes in neural nets for classification, though logistic-based or cross-entropy losses are more common there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward\n",
    "The Hinge Loss is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Hinge}(y, \\hat{y}) &= \\max\\Bigl(0, 1 - y \\cdot \\hat{y}\\Bigr) \\\\\n",
    "&= \\max\\big(0,\\, 1 - y_i \\mathbf{w}\\cdot \\mathbf{x}_i + b)\\big)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $y$ is the true label in ${-1, +1}$\n",
    "- $\\hat{y}$ is the predicted score (often the output before a sign function)\n",
    "- $x_i$ is the input $i$-th sample\n",
    "- $\\mathbf{w}$ is the weight/parameter vector of the model\n",
    "- $b$ is the bias vector of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss (per sample): [0.  1.5 1.5 0. ]\n",
      "Average Hinge Loss: 0.75\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, true labels must be either +1 or -1\n",
    "y_true = np.array([1, 1, -1, -1])\n",
    "y_pred = np.array([2.0, -0.5, 0.5, -2.0])  # some raw scores\n",
    "\n",
    "def hinge_loss(y_true, y_pred):\n",
    "    # hinge loss for each sample\n",
    "    losses = np.maximum(0, 1 - y_true * y_pred)\n",
    "    return losses\n",
    "\n",
    "hl = hinge_loss(y_true, y_pred)\n",
    "print(\"Hinge Loss (per sample):\", hl)\n",
    "print(\"Average Hinge Loss:\", np.mean(hl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward\n",
    "\n",
    "To find the derivative of $\\text{Hinge}(y, \\hat{y})$ with respect to $\\hat{y}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{Hinge}}{\\partial \\hat{y}} =\n",
    "\\begin{cases}\n",
    "0, & \\text{if } y \\cdot \\hat{y} \\geq 1 \\\\\n",
    "- y, & \\text{if } y \\cdot \\hat{y} < 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "The pushing of $\\hat{y}$ can be seen with this update function\n",
    "$$\n",
    "\\hat{y}_{new} = \\hat{y}_{old} - \\text{learning rate} \\cdot \\frac{\\partial \\text{Hinge}}{\\partial \\hat{y}}\n",
    "$$\n",
    "\n",
    "\n",
    "- Focus on Violations: The gradient is non-zero only when the prediction is within the margin or misclassified. This means the model only gets “punished” (and thus updated) when it makes an error or when the prediction is not confident enough. No update is applied if the prediction is correct and sufficiently confident (i.e., it exceeds the margin).\n",
    "- Constant Correction: The gradient value $-y$ is constant (it doesn’t depend on how far the prediction is from the margin). This creates a uniform push in the direction of the correct class. For instance, if a positive sample is not confident enough, the gradient will always be -1, signaling the need to increase the score regardless of the degree of error.\n",
    "- Sparsity in Updates: Because the gradient is zero for well-classified examples, the learning algorithm focuses on the “hard” examples where the decision boundary is ambiguous or incorrect, which is especially useful in classification tasks like those tackled by support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss gradient: [ 0. -1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "def hinge_loss_backward(y_true, y_pred):\n",
    "    # derivative of hinge loss for each sample\n",
    "    grad = np.zeros_like(y_pred)\n",
    "    mask = (1 - y_true * y_pred) > 0  # where hinge is active\n",
    "    grad[mask] = -y_true[mask]\n",
    "    return grad\n",
    "\n",
    "hl_grad = hinge_loss_backward(y_true, y_pred)\n",
    "print(\"Hinge Loss gradient:\", hl_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Loss\n",
    "\n",
    "Also known as the “pinball loss,” used in quantile regression. Given a quantile ($\\tau \\in (0,1)$).\n",
    "\n",
    "\n",
    "1.\tPredicting a Quantile Instead of the Mean\n",
    "    - Unlike MSE (which approximates the mean of the target variable), quantile loss tries to fit a particular quantile $\\tau\\in(0,1)$. For example:\n",
    "      - $\\tau=0.5$ = median regression (the model’s prediction is the median of y given the features)\n",
    "      - $\\tau=0.9$ = the model aims to be accurate at the 90th-percentile “high” end of y\n",
    "2.\tAsymmetric Penalty\n",
    "    - When $y > \\hat{y}$, the error contributes $\\tau \\times  (y - \\hat{y}) $\n",
    "    - When $y < \\hat{y}$, the error contributes $(\\tau-1)\\times (y - \\hat{y}) $\n",
    "    - Because $\\tau-1$ is negative if $\\tau<1$, this effectively penalizes overestimates differently than underestimates.\n",
    "3.\tRobustness and Distribution Insight\n",
    "    - By shifting $\\tau$, you can get a more complete picture of the conditional distribution of y. For instance, you might want to estimate the 0.05 (5th) or 0.95 (95th) quantiles for “worst-case” or “best-case” scenarios\n",
    "    - Median regression ($\\tau=0.5$) is more robust to outliers than MSE, because absolute deviations grow more slowly than squared deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward\n",
    "$$\n",
    "\\text{Quantile}(y, \\hat{y}; \\tau)\n",
    "= \\max\\biggl(\\tau (y - \\hat{y}), (\\tau - 1) (y - \\hat{y})\\biggr)\n",
    "$$\n",
    "\n",
    "Another common way to write it is piecewise:\n",
    "$$\n",
    "\\text{Quantile}(y, \\hat{y}; \\tau) =\n",
    "\\begin{cases}\n",
    "\\tau \\cdot (y - \\hat{y}) & \\text{if } y \\ge \\hat{y}, \\\\\n",
    "(\\tau - 1) \\cdot (y - \\hat{y}) & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y$ is the true value,\n",
    "- $\\hat{y}$ is the predicted value,\n",
    "- $\\tau$ is the quantile (e.g., 0.5 for median)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred=array([4. , 1. , 2.5]), y_true=array([5., 0., 3.])\n",
      "Quantile Loss: 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([5.0, 0.0, 3.0])\n",
    "y_pred = np.array([4.0, 1.0, 2.5])\n",
    "\n",
    "def quantile_loss(y_true, y_pred, quantile=0.5):\n",
    "    # e is the residual (error)\n",
    "    e = y_true - y_pred\n",
    "    # apply piecewise definition\n",
    "    loss = np.where(e >= 0, quantile * e, (quantile - 1) * e)\n",
    "    return np.mean(loss)\n",
    "\n",
    "ql_value = quantile_loss(y_true, y_pred, quantile=0.5)\n",
    "print(f\"{y_pred=}, {y_true=}\")\n",
    "print(\"Quantile Loss:\", ql_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward\n",
    "\n",
    "The derivative of the quantile loss with respect to $\\hat{y}$ depends on the sign of $y - \\hat{y}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{Quantile}}{\\partial \\hat{y}_i} =\n",
    "\\begin{cases}\n",
    "-\\tau, & \\text{if } y_i > \\hat{y}_i, \\\\\n",
    "-(1 - \\tau), & \\text{if } y_i < \\hat{y}_i, \\\\\n",
    "\\text{any value in between} \\; [-\\tau, -(1-\\tau)], & \\text{if } y_i = \\hat{y}_i.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred=array([4. , 1. , 2.5]), y_true=array([5., 0., 3.])\n",
      "Quantile Loss gradient: [-0.5  0.5 -0.5]\n"
     ]
    }
   ],
   "source": [
    "def quantile_loss_backward(y_true, y_pred, quantile=0.5):\n",
    "    error = y_true - y_pred\n",
    "    grad = np.zeros_like(y_pred)\n",
    "    grad[error > 0] = -quantile\n",
    "    grad[error < 0] = (1 - quantile)\n",
    "    # error == 0: can be any value in [-quantile, -(1-quantile)]\n",
    "    return grad\n",
    "\n",
    "ql_grad = quantile_loss_backward(y_true, y_pred, quantile=0.5)\n",
    "print(f\"{y_pred=}, {y_true=}\")\n",
    "print(\"Quantile Loss gradient:\", ql_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
